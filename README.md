<div align="center">

<img src="https://raw.githubusercontent.com/luna-ai-lab/DH-FaceVid-1K/main/assets/logo.svg" alt="DH-FaceVid-1K Logo" width="150">


# DH-FaceVid-1K: A Large-Scale High-Quality Dataset for Face Video Generation

<span style="font-size: 24px; font-weight: bold;">üèÜ ICCV 2025 üèÜ</span>

[![Paper](https://img.shields.io/badge/arXiv-Paper-b31b1b?logo=arxiv&logoColor=b31b1b)](https://arxiv.org/abs/2410.07151)
[![Project Website](https://img.shields.io/badge/DH--FaceVid--1K-Website-4CAF50?logo=googlechrome&logoColor=white)](https://dh-facevid-1k.github.io/DH-FaceVid-1K/)
[![Dataset v1.0](https://img.shields.io/badge/Request_Access-v1.0-8A2BE2?style=flat&logo=apache-spark&logoColor=white)](https://forms.gle/vEyouWdS9CgcRFMt9)

</div>

Official repository of **‚Äã‚ÄãDH-FaceVid-1K: A Large-Scale High-Quality Dataset for Face Video Generation**.

*[Donglin Di](https://scholar.google.com/citations?hl=zh-CN&user=L8tcNioAAAAJ), [He Feng](https://github.com/fenghe12), [Wenzhang Sun](https://scholar.google.hk/citations?user=3-9aEOQAAAAJ&hl=zh-CN&oi=ao), [Yongjia Ma](https://scholar.google.hk/citations?user=BszRJxkAAAAJ&hl=zh-CN&oi=ao), [Hao Li](#), [Chen Wei](#), [Lei Fan](https://hellodfan.github.io/), [Tonghua Su](https://scholar.google.hk/citations?hl=zh-CN&user=67fxVzoAAAAJ), [Xun Yang](https://scholar.google.hk/citations?hl=zh-CN&user=ro8lzsUAAAAJ)*

---

## üìñ Dataset Overview

![Dataset Overview](static/images/1.png)

Overview of DH-FaceVid-1K Dataset. It consists of 270,043 video clips along with corresponding spoken audio and annotations, featuring more than 20,000 unique identities and over 1,200 hours of facial video footage captured under various environmental conditions and lighting scenarios. Notably, 83% of the dataset represents Asian individuals, addressing the significant shortage of open-source Asian face video datasets.

---

## üì• Download

**Scale:** 270k samples / 1.2k hrs duration / ~4.01 TB

If you wish to download the DH-FaceVid-1K dataset, please follow these steps:

1.  **Fill out the request form**: To prevent misuse of the dataset, we require you to submit information for review and approval. Please carefully fill out [**this form**](https://forms.gle/vEyouWdS9CgcRFMt9). **You must use an official institutional email address and clearly state your research purpose.** Requests from personal email providers (e.g., Gmail, Outlook) will be rejected. When filling out the form, ensure your information is accurate, especially **your email address**, as this is where we will send the download instructions.

2.  **Await email delivery**: Once we receive and approve your submission, we will send you an email with download instructions, typically **within 2-3 days**. Please keep an eye on your inbox, including the spam or junk mail folders, to avoid missing our message.

3.  **Download the dataset**: After receiving the email, you can click the download link provided and follow the instructions on the page to complete the download process. If you encounter any issues or do not receive the email within a reasonable time, please contact us at **fenghe021209@gmail.com**.

**Note:** These video samples are sourced from crowd-sourcing platforms. To ensure the proper use of the data and prevent misuse, we manually review all download requests. By downloading and using this dataset, you are required to comply with [**the license agreement**](https://github.com/luna-ai-lab/DH-FaceVid-1K/blob/main/LICENSE). Thank you for your understanding and cooperation.

---

## üöÄ Open-source Plan

Our open-source roadmap is as follows. We will update the status here as we make progress.

- [x] **Phase 1:** Open filtered public datasets video ID list *(In Progress)*
- [x] **Phase 2:** Open 10% of total data *(In Progress)*
- [ ] **Phase 3:** Open 40% of total data
- [ ] **Phase 4:** Open 50% of total data

---

## üé¨ Video Samples

<table class="center" style="border-collapse: collapse; margin: auto;">
  <!-- Row 1 -->
  <tr>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/000680.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/001106.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/001406.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/001592.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/002148.gif" style="width: 100%;"></td>
  </tr>
  <!-- Row 2 -->
  <tr>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/002728.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/003696.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/005192.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/007956.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/008001.gif" style="width: 100%;"></td>
  </tr>
  <!-- Row 3 -->
  <tr>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/019479.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/026237.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/034785.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/039691.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/046378.gif" style="width: 100%;"></td>
  </tr>
  <!-- Row 4 -->
  <tr>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/061175.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/092616.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/105369.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/106321.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/14435.gif" style="width: 100%;"></td>
  </tr>
  <!-- Row 5: Alphanumeric IDs -->
  <tr>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/0s1UUn9aSSw_7.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/39Br2A7lxac_22.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/3lfO6OCqcCA_0.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/BFs-a-hqs2I_9.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/Czb5Ml9VDsI_0.gif" style="width: 100%;"></td>
  </tr>
  <!-- Row 6: More Alphanumeric IDs -->
  <tr>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/GrjEDguF59Q_0.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/hM3nn30NxCE_0.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/PP9l4LP0WPI_0.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/qfEkv726kdQ_6.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/qnFWCagTOtw_1.gif" style="width: 100%;"></td>
  </tr>
  <!-- Row 7: Final Selection with Complex Names -->
  <tr>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/Uu3xazfdmvk_34.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/V4cpZlFESeA_87.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/V4ZyJR30wyg_29.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/WN2XSI6vZIg_18.gif" style="width: 100%;"></td>
    <td width="20%" style="border: none; padding: 5px;"><img src="facevid/gifs/RS127710_segment_005_745_0.gif" style="width: 100%;"></td>
  </tr>
</table>

---

## üìä Datasets Comparison

Compared with other datasets, DH-FaceVid-1K has a larger data volume, competitive quality, and richer attribute annotations.

![Comparison](static/images/comparison.jpg)

---

## üìà Statistics

Distributions of general appearances, hair colors, emotions, actions, ethnicity, and age.

![Statistics](static/images/figure4.jpg)

---

## ‚öôÔ∏è Collection Pipeline

![Collection Pipeline](static/images/collect_pipe.png)

Illustration of the processing pipeline for collecting the DH-FaceVid-1K dataset. The main steps include:

1.  **Video Collection**: Collecting raw videos from **crowdsourcing platforms**.
2.  **Region Processing**: Detecting face regions, assessing their **resolution**, and cropping to the face and torso.
3.  **Quality Filtering**: Filtering out noisy clips, such as those with **embedded subtitles** or **occluding hands**.
4.  **Attribute Annotation**: Generating video descriptions that accurately profile the subject's **ethnicity, gender, age, expression, and attire**.
## üìã Comprehensive Attribute List

Comprehensive attribute list of DH-FaceVid-1K, including ethnicities, appearance details, emotions, actions, and lighting conditions.

![Attributes](static/images/detail.png)

---

## üß† Trained Models

**[Coming Soon]**

---

## ‚úíÔ∏è Citation

If you find the DH-FaceVid-1K dataset useful for your work, please consider citing our paper:
@inproceedings{di2025facevid,
title = {DH-FaceVid-1K: A Large-Scale High-Quality Dataset for Face Video Generation},
author = {Di, Donglin and Feng, He and Sun, Wenzhang and Ma, Yongjia and Li, Hao and Chen, Wei and Fan, Lei and Su, Tonghua and Yang, Xun},
booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
year = {2025}
}